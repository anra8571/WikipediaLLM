# Finetuning and Evaluating a Language Model
In this notebook, we do the following tasks:
 * Examine & Evaluate the Wikipedia dataset (98k+ question/answer pairs)
 * Clean up the Wikipedia dataset
 * Examine & Evaluate the class dataset (500+ question/answer pairs made by peers)
 * Clean up the class dataset
 * Run the model from Assignment 6 on the class dataset (provided in the repository)
 * Finetune BERT-mini on the Wikipedia dataset
 * Run the Wikipedia finetuned model on the class dataset
 * Summarize your findings

# Credits
Instructor: Philip Ogren

Semester: Fall 2024

Class: Natural Language Processing

University of Colorado Boulder
