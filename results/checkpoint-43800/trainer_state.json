{
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 8.0,
  "eval_steps": 500,
  "global_step": 43800,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.091324200913242,
      "grad_norm": 4.419846534729004,
      "learning_rate": 9.885844748858449e-06,
      "loss": 5.9383,
      "step": 500
    },
    {
      "epoch": 0.182648401826484,
      "grad_norm": 3.6807937622070312,
      "learning_rate": 9.771689497716895e-06,
      "loss": 5.9188,
      "step": 1000
    },
    {
      "epoch": 0.273972602739726,
      "grad_norm": 3.983672857284546,
      "learning_rate": 9.657534246575343e-06,
      "loss": 5.9027,
      "step": 1500
    },
    {
      "epoch": 0.365296803652968,
      "grad_norm": 6.158505916595459,
      "learning_rate": 9.543378995433791e-06,
      "loss": 5.8443,
      "step": 2000
    },
    {
      "epoch": 0.45662100456621,
      "grad_norm": 15.835381507873535,
      "learning_rate": 9.429223744292239e-06,
      "loss": 5.7689,
      "step": 2500
    },
    {
      "epoch": 0.547945205479452,
      "grad_norm": 18.888456344604492,
      "learning_rate": 9.315068493150685e-06,
      "loss": 5.7329,
      "step": 3000
    },
    {
      "epoch": 0.639269406392694,
      "grad_norm": 19.700145721435547,
      "learning_rate": 9.200913242009133e-06,
      "loss": 5.6999,
      "step": 3500
    },
    {
      "epoch": 0.730593607305936,
      "grad_norm": 15.087158203125,
      "learning_rate": 9.086757990867581e-06,
      "loss": 5.664,
      "step": 4000
    },
    {
      "epoch": 0.821917808219178,
      "grad_norm": 15.678123474121094,
      "learning_rate": 8.972602739726028e-06,
      "loss": 5.6464,
      "step": 4500
    },
    {
      "epoch": 0.91324200913242,
      "grad_norm": 24.471763610839844,
      "learning_rate": 8.858447488584476e-06,
      "loss": 5.628,
      "step": 5000
    },
    {
      "epoch": 1.0,
      "eval_loss": NaN,
      "eval_runtime": 161.2133,
      "eval_samples_per_second": 543.373,
      "eval_steps_per_second": 67.922,
      "step": 5475
    },
    {
      "epoch": 1.004566210045662,
      "grad_norm": 11.719157218933105,
      "learning_rate": 8.744292237442924e-06,
      "loss": 5.6134,
      "step": 5500
    },
    {
      "epoch": 1.095890410958904,
      "grad_norm": 18.84012794494629,
      "learning_rate": 8.63013698630137e-06,
      "loss": 5.5659,
      "step": 6000
    },
    {
      "epoch": 1.187214611872146,
      "grad_norm": 18.14989471435547,
      "learning_rate": 8.515981735159818e-06,
      "loss": 5.5656,
      "step": 6500
    },
    {
      "epoch": 1.278538812785388,
      "grad_norm": 17.380817413330078,
      "learning_rate": 8.401826484018264e-06,
      "loss": 5.5449,
      "step": 7000
    },
    {
      "epoch": 1.36986301369863,
      "grad_norm": 12.334009170532227,
      "learning_rate": 8.287671232876712e-06,
      "loss": 5.5301,
      "step": 7500
    },
    {
      "epoch": 1.461187214611872,
      "grad_norm": 13.575982093811035,
      "learning_rate": 8.17351598173516e-06,
      "loss": 5.5175,
      "step": 8000
    },
    {
      "epoch": 1.5525114155251143,
      "grad_norm": 10.203840255737305,
      "learning_rate": 8.059360730593608e-06,
      "loss": 5.503,
      "step": 8500
    },
    {
      "epoch": 1.643835616438356,
      "grad_norm": 12.346539497375488,
      "learning_rate": 7.945205479452055e-06,
      "loss": 5.4872,
      "step": 9000
    },
    {
      "epoch": 1.7351598173515983,
      "grad_norm": 9.262178421020508,
      "learning_rate": 7.831050228310503e-06,
      "loss": 5.4751,
      "step": 9500
    },
    {
      "epoch": 1.82648401826484,
      "grad_norm": 18.53404426574707,
      "learning_rate": 7.71689497716895e-06,
      "loss": 5.4602,
      "step": 10000
    },
    {
      "epoch": 1.9178082191780823,
      "grad_norm": 14.680740356445312,
      "learning_rate": 7.6027397260273985e-06,
      "loss": 5.4636,
      "step": 10500
    },
    {
      "epoch": 2.0,
      "eval_loss": NaN,
      "eval_runtime": 161.0069,
      "eval_samples_per_second": 544.07,
      "eval_steps_per_second": 68.01,
      "step": 10950
    },
    {
      "epoch": 2.009132420091324,
      "grad_norm": 16.890052795410156,
      "learning_rate": 7.488584474885845e-06,
      "loss": 5.478,
      "step": 11000
    },
    {
      "epoch": 2.1004566210045663,
      "grad_norm": 16.61564826965332,
      "learning_rate": 7.374429223744293e-06,
      "loss": 5.4241,
      "step": 11500
    },
    {
      "epoch": 2.191780821917808,
      "grad_norm": 15.133599281311035,
      "learning_rate": 7.260273972602741e-06,
      "loss": 5.4188,
      "step": 12000
    },
    {
      "epoch": 2.2831050228310503,
      "grad_norm": 16.415828704833984,
      "learning_rate": 7.146118721461188e-06,
      "loss": 5.3958,
      "step": 12500
    },
    {
      "epoch": 2.374429223744292,
      "grad_norm": 12.565829277038574,
      "learning_rate": 7.031963470319635e-06,
      "loss": 5.4095,
      "step": 13000
    },
    {
      "epoch": 2.4657534246575343,
      "grad_norm": 14.8951416015625,
      "learning_rate": 6.917808219178082e-06,
      "loss": 5.4187,
      "step": 13500
    },
    {
      "epoch": 2.557077625570776,
      "grad_norm": 16.712430953979492,
      "learning_rate": 6.80365296803653e-06,
      "loss": 5.4001,
      "step": 14000
    },
    {
      "epoch": 2.6484018264840183,
      "grad_norm": 22.757869720458984,
      "learning_rate": 6.689497716894978e-06,
      "loss": 5.4029,
      "step": 14500
    },
    {
      "epoch": 2.73972602739726,
      "grad_norm": 13.576946258544922,
      "learning_rate": 6.5753424657534245e-06,
      "loss": 5.3784,
      "step": 15000
    },
    {
      "epoch": 2.8310502283105023,
      "grad_norm": 12.1680326461792,
      "learning_rate": 6.4611872146118725e-06,
      "loss": 5.3737,
      "step": 15500
    },
    {
      "epoch": 2.922374429223744,
      "grad_norm": 17.812673568725586,
      "learning_rate": 6.3470319634703205e-06,
      "loss": 5.377,
      "step": 16000
    },
    {
      "epoch": 3.0,
      "eval_loss": NaN,
      "eval_runtime": 160.6432,
      "eval_samples_per_second": 545.302,
      "eval_steps_per_second": 68.163,
      "step": 16425
    },
    {
      "epoch": 3.0136986301369864,
      "grad_norm": 12.184672355651855,
      "learning_rate": 6.2328767123287685e-06,
      "loss": 5.3774,
      "step": 16500
    },
    {
      "epoch": 3.105022831050228,
      "grad_norm": 16.031757354736328,
      "learning_rate": 6.118721461187215e-06,
      "loss": 5.3219,
      "step": 17000
    },
    {
      "epoch": 3.1963470319634704,
      "grad_norm": 30.936784744262695,
      "learning_rate": 6.004566210045663e-06,
      "loss": 5.3421,
      "step": 17500
    },
    {
      "epoch": 3.287671232876712,
      "grad_norm": 16.787887573242188,
      "learning_rate": 5.89041095890411e-06,
      "loss": 5.3351,
      "step": 18000
    },
    {
      "epoch": 3.3789954337899544,
      "grad_norm": 14.047788619995117,
      "learning_rate": 5.776255707762558e-06,
      "loss": 5.3138,
      "step": 18500
    },
    {
      "epoch": 3.470319634703196,
      "grad_norm": 16.972522735595703,
      "learning_rate": 5.662100456621005e-06,
      "loss": 5.3156,
      "step": 19000
    },
    {
      "epoch": 3.5616438356164384,
      "grad_norm": 14.996274948120117,
      "learning_rate": 5.547945205479452e-06,
      "loss": 5.3248,
      "step": 19500
    },
    {
      "epoch": 3.65296803652968,
      "grad_norm": 10.833563804626465,
      "learning_rate": 5.4337899543379e-06,
      "loss": 5.3211,
      "step": 20000
    },
    {
      "epoch": 3.7442922374429224,
      "grad_norm": 17.02797508239746,
      "learning_rate": 5.319634703196348e-06,
      "loss": 5.315,
      "step": 20500
    },
    {
      "epoch": 3.8356164383561646,
      "grad_norm": 20.123620986938477,
      "learning_rate": 5.2054794520547945e-06,
      "loss": 5.3004,
      "step": 21000
    },
    {
      "epoch": 3.9269406392694064,
      "grad_norm": 16.326379776000977,
      "learning_rate": 5.0913242009132425e-06,
      "loss": 5.3045,
      "step": 21500
    },
    {
      "epoch": 4.0,
      "eval_loss": NaN,
      "eval_runtime": 161.1609,
      "eval_samples_per_second": 543.55,
      "eval_steps_per_second": 67.945,
      "step": 21900
    },
    {
      "epoch": 4.018264840182648,
      "grad_norm": 20.611112594604492,
      "learning_rate": 4.97716894977169e-06,
      "loss": 5.2758,
      "step": 22000
    },
    {
      "epoch": 4.109589041095891,
      "grad_norm": 12.545792579650879,
      "learning_rate": 4.863013698630138e-06,
      "loss": 5.2595,
      "step": 22500
    },
    {
      "epoch": 4.200913242009133,
      "grad_norm": 9.147820472717285,
      "learning_rate": 4.748858447488585e-06,
      "loss": 5.2482,
      "step": 23000
    },
    {
      "epoch": 4.292237442922374,
      "grad_norm": 19.038040161132812,
      "learning_rate": 4.634703196347032e-06,
      "loss": 5.2651,
      "step": 23500
    },
    {
      "epoch": 4.383561643835616,
      "grad_norm": 16.048364639282227,
      "learning_rate": 4.52054794520548e-06,
      "loss": 5.2304,
      "step": 24000
    },
    {
      "epoch": 4.474885844748858,
      "grad_norm": 15.40764045715332,
      "learning_rate": 4.406392694063927e-06,
      "loss": 5.2633,
      "step": 24500
    },
    {
      "epoch": 4.566210045662101,
      "grad_norm": 29.03386878967285,
      "learning_rate": 4.292237442922374e-06,
      "loss": 5.2775,
      "step": 25000
    },
    {
      "epoch": 4.657534246575342,
      "grad_norm": 17.961559295654297,
      "learning_rate": 4.178082191780822e-06,
      "loss": 5.2532,
      "step": 25500
    },
    {
      "epoch": 4.748858447488584,
      "grad_norm": 12.83298397064209,
      "learning_rate": 4.063926940639269e-06,
      "loss": 5.2488,
      "step": 26000
    },
    {
      "epoch": 4.840182648401827,
      "grad_norm": 28.48476219177246,
      "learning_rate": 3.949771689497717e-06,
      "loss": 5.2558,
      "step": 26500
    },
    {
      "epoch": 4.931506849315069,
      "grad_norm": 29.38134765625,
      "learning_rate": 3.8356164383561645e-06,
      "loss": 5.2523,
      "step": 27000
    },
    {
      "epoch": 5.0,
      "eval_loss": NaN,
      "eval_runtime": 161.2128,
      "eval_samples_per_second": 543.375,
      "eval_steps_per_second": 67.923,
      "step": 27375
    },
    {
      "epoch": 5.0228310502283104,
      "grad_norm": 11.095193862915039,
      "learning_rate": 3.721461187214612e-06,
      "loss": 5.2355,
      "step": 27500
    },
    {
      "epoch": 5.114155251141552,
      "grad_norm": 14.905438423156738,
      "learning_rate": 3.6073059360730597e-06,
      "loss": 5.228,
      "step": 28000
    },
    {
      "epoch": 5.205479452054795,
      "grad_norm": 17.894256591796875,
      "learning_rate": 3.4931506849315072e-06,
      "loss": 5.2223,
      "step": 28500
    },
    {
      "epoch": 5.296803652968037,
      "grad_norm": 15.610410690307617,
      "learning_rate": 3.3789954337899544e-06,
      "loss": 5.2384,
      "step": 29000
    },
    {
      "epoch": 5.3881278538812785,
      "grad_norm": 20.766294479370117,
      "learning_rate": 3.2648401826484024e-06,
      "loss": 5.2227,
      "step": 29500
    },
    {
      "epoch": 5.47945205479452,
      "grad_norm": 22.030197143554688,
      "learning_rate": 3.1506849315068495e-06,
      "loss": 5.2172,
      "step": 30000
    },
    {
      "epoch": 5.570776255707763,
      "grad_norm": 21.198591232299805,
      "learning_rate": 3.036529680365297e-06,
      "loss": 5.2037,
      "step": 30500
    },
    {
      "epoch": 5.662100456621005,
      "grad_norm": 18.644092559814453,
      "learning_rate": 2.9223744292237442e-06,
      "loss": 5.2079,
      "step": 31000
    },
    {
      "epoch": 5.7534246575342465,
      "grad_norm": 13.180135726928711,
      "learning_rate": 2.8082191780821922e-06,
      "loss": 5.2253,
      "step": 31500
    },
    {
      "epoch": 5.844748858447488,
      "grad_norm": 25.1848201751709,
      "learning_rate": 2.6940639269406394e-06,
      "loss": 5.1961,
      "step": 32000
    },
    {
      "epoch": 5.936073059360731,
      "grad_norm": 21.848651885986328,
      "learning_rate": 2.579908675799087e-06,
      "loss": 5.1805,
      "step": 32500
    },
    {
      "epoch": 6.0,
      "eval_loss": NaN,
      "eval_runtime": 161.386,
      "eval_samples_per_second": 542.792,
      "eval_steps_per_second": 67.85,
      "step": 32850
    },
    {
      "epoch": 6.027397260273973,
      "grad_norm": 23.474576950073242,
      "learning_rate": 2.4657534246575345e-06,
      "loss": 5.1753,
      "step": 33000
    },
    {
      "epoch": 6.1187214611872145,
      "grad_norm": 23.20252799987793,
      "learning_rate": 2.3515981735159817e-06,
      "loss": 5.2121,
      "step": 33500
    },
    {
      "epoch": 6.210045662100456,
      "grad_norm": 21.446767807006836,
      "learning_rate": 2.2374429223744292e-06,
      "loss": 5.176,
      "step": 34000
    },
    {
      "epoch": 6.301369863013699,
      "grad_norm": 16.913555145263672,
      "learning_rate": 2.123287671232877e-06,
      "loss": 5.1778,
      "step": 34500
    },
    {
      "epoch": 6.392694063926941,
      "grad_norm": 18.79900550842285,
      "learning_rate": 2.0091324200913244e-06,
      "loss": 5.1657,
      "step": 35000
    },
    {
      "epoch": 6.4840182648401825,
      "grad_norm": 17.53236198425293,
      "learning_rate": 1.8949771689497717e-06,
      "loss": 5.1745,
      "step": 35500
    },
    {
      "epoch": 6.575342465753424,
      "grad_norm": 16.58624839782715,
      "learning_rate": 1.7808219178082193e-06,
      "loss": 5.1841,
      "step": 36000
    },
    {
      "epoch": 6.666666666666667,
      "grad_norm": 18.591537475585938,
      "learning_rate": 1.6666666666666667e-06,
      "loss": 5.187,
      "step": 36500
    },
    {
      "epoch": 6.757990867579909,
      "grad_norm": 17.892770767211914,
      "learning_rate": 1.5525114155251142e-06,
      "loss": 5.1775,
      "step": 37000
    },
    {
      "epoch": 6.8493150684931505,
      "grad_norm": 24.512174606323242,
      "learning_rate": 1.4383561643835616e-06,
      "loss": 5.1644,
      "step": 37500
    },
    {
      "epoch": 6.940639269406392,
      "grad_norm": 19.334701538085938,
      "learning_rate": 1.3242009132420092e-06,
      "loss": 5.1924,
      "step": 38000
    },
    {
      "epoch": 7.0,
      "eval_loss": NaN,
      "eval_runtime": 160.6297,
      "eval_samples_per_second": 545.348,
      "eval_steps_per_second": 68.169,
      "step": 38325
    },
    {
      "epoch": 7.031963470319635,
      "grad_norm": 26.96171760559082,
      "learning_rate": 1.2100456621004567e-06,
      "loss": 5.185,
      "step": 38500
    },
    {
      "epoch": 7.123287671232877,
      "grad_norm": 16.553131103515625,
      "learning_rate": 1.095890410958904e-06,
      "loss": 5.1458,
      "step": 39000
    },
    {
      "epoch": 7.2146118721461185,
      "grad_norm": 18.832839965820312,
      "learning_rate": 9.817351598173517e-07,
      "loss": 5.1372,
      "step": 39500
    },
    {
      "epoch": 7.30593607305936,
      "grad_norm": 26.766164779663086,
      "learning_rate": 8.675799086757991e-07,
      "loss": 5.171,
      "step": 40000
    },
    {
      "epoch": 7.397260273972603,
      "grad_norm": 23.554662704467773,
      "learning_rate": 7.534246575342466e-07,
      "loss": 5.1749,
      "step": 40500
    },
    {
      "epoch": 7.488584474885845,
      "grad_norm": 19.345916748046875,
      "learning_rate": 6.39269406392694e-07,
      "loss": 5.1702,
      "step": 41000
    },
    {
      "epoch": 7.579908675799087,
      "grad_norm": 29.46967315673828,
      "learning_rate": 5.251141552511415e-07,
      "loss": 5.1379,
      "step": 41500
    },
    {
      "epoch": 7.671232876712329,
      "grad_norm": 14.772440910339355,
      "learning_rate": 4.1095890410958903e-07,
      "loss": 5.1475,
      "step": 42000
    },
    {
      "epoch": 7.762557077625571,
      "grad_norm": 15.06493854522705,
      "learning_rate": 2.9680365296803655e-07,
      "loss": 5.1669,
      "step": 42500
    },
    {
      "epoch": 7.853881278538813,
      "grad_norm": 19.700803756713867,
      "learning_rate": 1.8264840182648401e-07,
      "loss": 5.1299,
      "step": 43000
    },
    {
      "epoch": 7.945205479452055,
      "grad_norm": 23.843915939331055,
      "learning_rate": 6.84931506849315e-08,
      "loss": 5.181,
      "step": 43500
    }
  ],
  "logging_steps": 500,
  "max_steps": 43800,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 8,
  "save_steps": 500,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": true
      },
      "attributes": {}
    }
  },
  "total_flos": 5102320832114688.0,
  "train_batch_size": 16,
  "trial_name": null,
  "trial_params": null
}
